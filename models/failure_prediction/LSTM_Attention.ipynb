{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"6_LSTM_Attention.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YQ6lT1e2hrx4","executionInfo":{"status":"ok","timestamp":1632410051894,"user_tz":-330,"elapsed":22716,"user":{"displayName":"Girish L","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFYUUS_32MqAdpAZEVQJ6OCQY0GdRRslhgRs3N4A=s64","userId":"17486224615133974293"}},"outputId":"8d58bf24-03aa-41cb-a246-63c5f376e07a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"tLhroy5BnMnC","executionInfo":{"status":"ok","timestamp":1632410056918,"user_tz":-330,"elapsed":1819,"user":{"displayName":"Girish L","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFYUUS_32MqAdpAZEVQJ6OCQY0GdRRslhgRs3N4A=s64","userId":"17486224615133974293"}}},"source":["# Importing libraries\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","import pandas as pd\n","import numpy as np\n","import os"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2-UpMVsSnfCI","executionInfo":{"status":"error","timestamp":1632410059851,"user_tz":-330,"elapsed":583,"user":{"displayName":"Girish L","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgFYUUS_32MqAdpAZEVQJ6OCQY0GdRRslhgRs3N4A=s64","userId":"17486224615133974293"}},"outputId":"9d94cdad-1852-4e40-ce9e-43edb5fdc7ba"},"source":["df_Ellis  = pd.read_csv(\"/content/drive/MyDrive/Failure/lstm/Ellis_FinalTwoConditionwithOR.csv\")\n","df_Ellis"],"execution_count":3,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-02d18c61e160>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_Ellis\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Failure/lstm/Ellis_FinalTwoConditionwithOR.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_Ellis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Failure/lstm/Ellis_FinalTwoConditionwithOR.csv'"]}]},{"cell_type":"code","metadata":{"id":"92xBt43BnjAo"},"source":["df_Ellis.plot()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RSo-aa-SIoBR"},"source":["# we show here the hist\n","df_Ellis.hist(bins=100,figsize=(20,15))\n","#save_fig(\"attribute_histogram_plots\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gggaMJ_2LtFs"},"source":["cpu_system_perc = df_Ellis[['ellis-cpu.system_perc']] \n","cpu_system_perc.rolling(12).mean().plot(figsize=(20,10), linewidth=5, fontsize=20) \n","plt.xlabel('Timestamp', fontsize=30);"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R_ctvXcQL1Xf"},"source":["load_avg_1_min = df_Ellis[['ellis-load.avg_1_min']] \n","load_avg_1_min.rolling(12).mean().plot(figsize=(20,10), linewidth=5, fontsize=20) \n","plt.xlabel('Timestamp', fontsize=30);"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gkd5ecCmL6Bw"},"source":["cpu_wait_perc = df_Ellis[['ellis-cpu.wait_perc']] \n","cpu_wait_perc.rolling(12).mean().plot(figsize=(20,10), linewidth=5, fontsize=20) \n","plt.xlabel('Year', fontsize=30);"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EycZrQU0MBSX"},"source":["df_dg = pd.concat([cpu_system_perc.rolling(12).mean(), load_avg_1_min.rolling(12).mean(),cpu_wait_perc.rolling(12).mean()], axis=1) \n","df_dg.plot(figsize=(20,10), linewidth=5, fontsize=20) \n","plt.xlabel('Year', fontsize=20); "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YoQA_MIBMknS"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pi8UMMitMa3Q"},"source":["# we establish the corrmartrice\n","import seaborn as sns\n","color = sns.color_palette()\n","sns.set_style('darkgrid')\n","\n","correaltionMatrice = df_Ellis.corr()\n","f, ax = plt.subplots(figsize=(20, 10))\n","sns.heatmap(correaltionMatrice, cbar=True, vmin=0, vmax=1, square=True, annot=True);\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rkYwyKtXMvpy"},"source":["df_Ellis.corrwith(df_Ellis['ellis-load.avg_1_min'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5oQK-ddinvCM"},"source":["## ## using multivariate feature \n","\n","features_3 = ['ellis-cpu.wait_perc', 'ellis-load.avg_1_min', 'ellis-net.in_bytes_sec', 'Label']\n","\n","features = df_Ellis[features_3]\n","features.index = df_Ellis['Timestamp']\n","features.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qbqn755fo81g"},"source":["features.plot(subplots=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jJQD1x9psWCH"},"source":["features = features.values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xf8WCiykpUzN"},"source":["### standardize data\n","train_split = 141600\n","tf.random.set_seed(13)\n","\n","### standardize data\n","features_mean = features[:train_split].mean()\n","features_std = features[:train_split].std()\n","features  = (features - features_mean)/ features_std\n","\n","print(type(features))\n","print(features.shape)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1a0hNDmppnLB"},"source":["### create mutlivariate data\n","\n","def mutlivariate_data(features , target , start_idx , end_idx , history_size , target_size,\n","                      step ,  single_step = False):\n","  data = []\n","  labels = []\n","  start_idx = start_idx + history_size\n","  if end_idx is None:\n","    end_idx = len(features)- target_size\n","  for i in range(start_idx , end_idx ):\n","    idxs = range(i-history_size, i, step) ### using step\n","    data.append(features[idxs])\n","    if single_step:\n","      labels.append(target[i+target_size])\n","    else:\n","      labels.append(target[i:i+target_size])\n","\n","  return np.array(data) , np.array(labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z0CivgkitfgE"},"source":["### generate multivariate data\n","\n","history = 720\n","future_target = 72\n","STEP = 6\n","\n","x_train_ss , y_train_ss = mutlivariate_data(features , features[:, 1], 0, train_split, history,\n","                                            future_target, STEP , single_step = True)\n","\n","x_val_ss , y_val_ss = mutlivariate_data(features , features[:,1] , train_split , None , history ,\n","                                        future_target, STEP, single_step = True)\n","\n","print(x_train_ss.shape , y_train_ss.shape)\n","print(x_val_ss.shape , y_val_ss.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VBdr2epGu3aq"},"source":["## tensorflow dataset\n","batch_size = 256\n","buffer_size = 10000\n","\n","train_ss = tf.data.Dataset.from_tensor_slices((x_train_ss, y_train_ss))\n","train_ss = train_ss.cache().shuffle(buffer_size).batch(batch_size).repeat()\n","\n","val_ss = tf.data.Dataset.from_tensor_slices((x_val_ss, y_val_ss))\n","val_ss = val_ss.cache().shuffle(buffer_size).batch(batch_size).repeat()\n","\n","print(train_ss)\n","print(val_ss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9eQpwUyGglu_"},"source":["def root_mean_squared_error(y_true, y_pred):\n","        return K.sqrt(K.mean(K.square(y_pred - y_true))) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"81S0BbNa7Rce"},"source":["import tensorflow as tf\n","from keras.layers import Activation, Dense, Dropout,Permute,Reshape,Lambda,dot,concatenate\n","\n","INPUT_DIM = 100\n","TIME_STEPS = 20\n","# if True, the attention vector is shared across the input_dimensions where the attention is applied.\n","SINGLE_ATTENTION_VECTOR = True\n","APPLY_ATTENTION_BEFORE_LSTM = False\n","\n","ATTENTION_SIZE = 128\n","\n","def attention_3d_block(hidden_states):\n","    # hidden_states.shape = (batch_size, time_steps, hidden_size)\n","    hidden_size = int(hidden_states.shape[2])\n","    # _t stands for transpose\n","    hidden_states_t =  Permute((2, 1), name='attention_input_t')(hidden_states)\n","    # hidden_states_t.shape = (batch_size, hidden_size, time_steps)\n","    # this line is not useful. It's just to know which dimension is what.\n","    hidden_states_t = Reshape((hidden_size, TIME_STEPS), name='attention_input_reshape')(hidden_states_t)\n","    # Inside dense layer\n","    # a (batch_size, hidden_size, time_steps) dot W (time_steps, time_steps) => (batch_size, hidden_size, time_steps)\n","    # W is the trainable weight matrix of attention\n","    # Luong's multiplicative style score\n","    score_first_part = Dense(TIME_STEPS, use_bias=False, name='attention_score_vec')(hidden_states_t)\n","    score_first_part_t = Permute((2, 1), name='attention_score_vec_t')(score_first_part)\n","    #            score_first_part_t         dot        last_hidden_state     => attention_weights\n","    # (batch_size, time_steps, hidden_size) dot (batch_size, hidden_size, 1) => (batch_size, time_steps, 1)\n","    h_t = Lambda(lambda x: x[:, :, -1], output_shape=(hidden_size, 1), name='last_hidden_state')(hidden_states_t)\n","    score = dot([score_first_part_t, h_t], [2, 1], name='attention_score')\n","    attention_weights = Activation('softmax', name='attention_weight')(score)\n","    # if SINGLE_ATTENTION_VECTOR:\n","    #     a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)\n","    #     a = RepeatVector(hidden_size)(a)\n","    # (batch_size, hidden_size, time_steps) dot (batch_size, time_steps, 1) => (batch_size, hidden_size, 1)\n","    context_vector = dot([hidden_states_t, attention_weights], [2, 1], name='context_vector')\n","    context_vector = Reshape((hidden_size,))(context_vector)\n","    h_t = Reshape((hidden_size,))(h_t)\n","    pre_activation = concatenate([context_vector, h_t], name='attention_output')\n","    attention_vector = Dense(ATTENTION_SIZE, use_bias=False, activation='tanh', name='attention_vector')(pre_activation)\n","    return attention_vector"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1cKtTAzqyiyL"},"source":["from keras.layers import Activation, Dense, Dropout\n","from keras.layers import Input, LSTM, merge ,Conv1D,Dropout,Bidirectional,Multiply,Flatten\n","from keras.models import Model\n","from keras.utils.vis_utils import plot_model\n","### Modelling using LSTM\n","steps = 50\n","TIME_STEPS=120\n","INPUT_DIMS=4\n","\n","EPOCHS =20\n","\n","single_step_model = tf.keras.models.Sequential()\n","\n","inputs = Input(shape=(120, 4))\n","lstm_units = 32\n","lstm_out = LSTM(lstm_units, return_sequences=True)(inputs)\n","lstm_out=tf.keras.layers.Dropout(0.6)(lstm_out)\n","attention_mul = attention_3d_block(lstm_out)\n","#attention_mul = Flatten()(attention_mul)\n","attention_mul=tf.keras.layers.Dropout(0.6)(attention_mul)\n","output = Dense(1, activation='sigmoid')(attention_mul)\n","\n","single_step_model = Model(inputs, output)\n","\n","  \n","single_step_model.summary()\n","\n","plot_model(single_step_model, to_file='/content/drive/MyDrive/Failure/lstm/LSTM-Attention-B.png', show_shapes=True, show_layer_names=True)\n","\n","single_step_model.compile(optimizer = tf.keras.optimizers.Adam(), loss = 'mae',metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n","#single_step_model.compile(loss='mse', optimizer='rmsprop')\n","\n"," "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"94000u5xIjWD"},"source":["single_step_model_history = single_step_model.fit(train_ss, epochs = EPOCHS , \n","                                                  steps_per_epoch =steps, validation_data = val_ss,\n","                                                  validation_steps = 50)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pgev0dgzzBVx"},"source":["## plot train test loss \n","\n","def plot_loss(history , title):\n","  loss = history.history['loss']\n","  val_loss = history.history['val_loss']\n","\n","  epochs = range(len(loss))\n","  plt.figure()\n","  plt.plot(epochs, loss , 'b' , label = 'Train Loss')\n","  plt.plot(epochs, val_loss , 'r' , label = 'Validation Loss')\n","  plt.title(title)\n","  plt.legend()\n","  plt.grid()\n","  plt.show()\n","\n","plot_loss(single_step_model_history , 'Single Step Training and validation loss')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EnYf6j4okEoC"},"source":["## plot train test loss \n","\n","def plot_loss(history , title):\n","  loss = history.history['rmse']\n","  val_loss = history.history['val_rmse']\n","\n","  epochs = range(len(loss))\n","  plt.figure()\n","  plt.plot(epochs, loss , 'b' , label = 'Train RMSE')\n","  plt.plot(epochs, val_loss , 'r' , label = 'Validation RMSE')\n","  plt.title(title)\n","  plt.legend()\n","  plt.grid()\n","  plt.show()\n","\n","plot_loss(single_step_model_history , 'Single Step Training and validation loss')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WMegV8mNAwe_"},"source":["### fucntion to create time steps\n","def create_time_steps(length):\n","  return list(range(-length,0))\n","\n","### function to plot time series data\n","\n","def plot_time_series(plot_data, delta , title):\n","  labels = [\"History\" , 'True Future' , 'Model Predcited']\n","  marker = ['.-' , 'rx' , 'go']\n","  time_steps = create_time_steps(plot_data[0].shape[0])\n","\n","  if delta:\n","    future = delta\n","  else:\n","    future = 0\n","  plt.title(title)\n","  for i , x in enumerate(plot_data):\n","    if i :\n","      plt.plot(future , plot_data[i] , marker[i], markersize = 10 , label = labels[i])\n","    else:\n","      plt.plot(time_steps, plot_data[i].flatten(), marker[i], label = labels[i])\n","  plt.legend()\n","  plt.xlim([time_steps[0], (future+5) *2])\n","\n","  plt.xlabel('Time_Step')\n","  return plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q99i2c-9XKF3"},"source":["### Moving window average\n","\n","def MWA(history):\n","  return np.mean(history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xFJT1rZDAUVL"},"source":["# plot time series and predicted values\n","\n","for x, y in val_ss.take(5):\n","  plot = plot_time_series([x[0][:, 1].numpy(), y[0].numpy(),\n","                    single_step_model.predict(x)[0]], 12,\n","                   'Single Step Prediction')\n","  plot.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_KXWQVmyCSix"},"source":["# **MultiStep Forcasting**"]},{"cell_type":"code","metadata":{"id":"Lu7m2Rr4AbMK"},"source":["future_target = 72 # 72 future values\n","x_train_multi, y_train_multi = mutlivariate_data(features, features[:, 1], 0,\n","                                                 train_split, history,\n","                                                 future_target, STEP)\n","x_val_multi, y_val_multi = mutlivariate_data(features, features[:, 1],\n","                                             train_split, None, history,\n","                                             future_target, STEP)\n","\n","print(x_train_multi.shape)\n","print(y_train_multi.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GLRv5D16CrHj"},"source":["#  TF DATASET\n","\n","train_data_multi = tf.data.Dataset.from_tensor_slices((x_train_multi, y_train_multi))\n","train_data_multi = train_data_multi.cache().shuffle(buffer_size).batch(batch_size).repeat()\n","\n","val_data_multi = tf.data.Dataset.from_tensor_slices((x_val_multi, y_val_multi))\n","val_data_multi = val_data_multi.batch(batch_size).repeat()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fjXexah9C8yg"},"source":["print(train_data_multi)\n","print(val_data_multi)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7mtLZ6S-DPU-"},"source":["#plotting function\n","def multi_step_plot(history, true_future, prediction):\n","  plt.figure(figsize=(12, 6))\n","  num_in = create_time_steps(len(history))\n","  num_out = len(true_future)\n","  plt.grid()\n","  plt.plot(num_in, np.array(history[:, 1]), label='History')\n","  plt.plot(np.arange(num_out)/STEP, np.array(true_future), 'bo',\n","           label='True Future')\n","  if prediction.any():\n","    plt.plot(np.arange(num_out)/STEP, np.array(prediction), 'ro',\n","             label='Predicted Future')\n","  plt.legend(loc='upper left')\n","  plt.show()\n","  \n","\n","\n","for x, y in train_data_multi.take(1):\n","  multi_step_plot(x[0], y[0], np.array([0]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"snN_Flr5DWQN"},"source":["multi_step_model = tf.keras.models.Sequential()\n","\n","inputs = Input(shape=(120, 4))\n","lstm_units = 32\n","lstm_out = LSTM(lstm_units, return_sequences=True)(inputs)\n","lstm_out=tf.keras.layers.Dropout(0.6)(lstm_out)\n","attention_mul = attention_3d_block(lstm_out)\n","#attention_mul = Flatten()(attention_mul)\n","attention_mul=tf.keras.layers.Dropout(0.6)(attention_mul)\n","output = Dense(1, activation='sigmoid')(attention_mul)\n","\n","multi_step_model = Model(inputs, output)\n","multi_step_model.compile(optimizer=tf.keras.optimizers.RMSprop(clipvalue=1.0), loss='mae',metrics=[tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n","\n","multi_step_history = multi_step_model.fit(train_data_multi, epochs=EPOCHS,\n","                                          steps_per_epoch=steps,\n","                                          validation_data=val_data_multi,\n","                                          validation_steps=50)\n","multi_step_model.summary()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ay5m27doDsTt"},"source":["plot_loss(multi_step_history, 'Multi-Step Training and validation loss')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ZFP49W4D2wp"},"source":["for x, y in val_data_multi.take(5):\n","  multi_step_plot(x[0], y[0], multi_step_model.predict(x)[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DNKMjVoAVqZP"},"source":["scores = multi_step_model.evaluate(x_train_multi, y_train_multi, verbose=1, batch_size=200)\n","print('MAE: {}'.format(scores[1]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YXcsNZ8yu9Ay"},"source":["scores_test = multi_step_model.evaluate(x_val_multi, y_val_multi, verbose=1, batch_size=200)\n","print('MAE: {}'.format(scores[1]))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uCFgbZEOvZ9A"},"source":["y_pred_test = multi_step_model.predict(x_val_multi, verbose=0)\n","\n","plt.figure(figsize=(10,5))\n","plt.plot(y_pred_test)\n","plt.plot(y_val_multi)\n","plt.ylabel(\"RUL\")\n","plt.xlabel(\"Unit Number\")\n","plt.legend(loc='upper left')\n","plt.show()"],"execution_count":null,"outputs":[]}]}